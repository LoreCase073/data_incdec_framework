{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports to work with...\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from cl_framework.continual_learning.metrics.metric_evaluator_incdec import MetricEvaluatorIncDec\n",
    "from cl_framework.utilities.matrix_logger import IncDecLogger\n",
    "from torchmetrics import Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            video_path  prediction  target  \\\n",
      "0    ./Kinetics/Videos/id_7qahQViiGlk_000136_000146...           1       0   \n",
      "1    ./Kinetics/Videos/id_81ygRCk7Hz8_000000_000010...           4       0   \n",
      "2    ./Kinetics/Videos/id_825Fw81OywM_000028_000038...           0       0   \n",
      "3    ./Kinetics/Videos/id_863uabO7S5k_000059_000069...           4       0   \n",
      "4    ./Kinetics/Videos/id_893XEXlkHeU_000002_000012...           0       0   \n",
      "..                                                 ...         ...     ...   \n",
      "365  ./Kinetics/Videos/id_JJP5kAysTXI_000014_000024...           4       4   \n",
      "366  ./Kinetics/Videos/id_JNy7CjCeDmg_000000_000010...           4       4   \n",
      "367  ./Kinetics/Videos/id_JOAKjYyi7Pg_000116_000126...           4       4   \n",
      "368  ./Kinetics/Videos/id_JOB4yy5Jyds_000120_000130...           0       4   \n",
      "369  ./Kinetics/Videos/id_JQyRW2zUptU_000102_000112...           0       4   \n",
      "\n",
      "       subcategory      food     phone   smoking   fatigue  selfcare  \n",
      "0    eating burger  0.052392  0.563979  0.120312  0.088279  0.175037  \n",
      "1    eating burger  0.257734  0.099156  0.144065  0.206720  0.292325  \n",
      "2    eating burger  0.318925  0.115136  0.200017  0.310198  0.055725  \n",
      "3    eating burger  0.120902  0.156681  0.158121  0.182211  0.382085  \n",
      "4    eating burger  0.363266  0.066142  0.122788  0.176259  0.271545  \n",
      "..             ...       ...       ...       ...       ...       ...  \n",
      "365    dyeing hair  0.334259  0.129802  0.061846  0.074579  0.399514  \n",
      "366    dyeing hair  0.058048  0.007517  0.010389  0.021162  0.902883  \n",
      "367    dyeing hair  0.133767  0.103926  0.107850  0.139633  0.514825  \n",
      "368    dyeing hair  0.327112  0.145765  0.167402  0.196519  0.163202  \n",
      "369    dyeing hair  0.337021  0.258708  0.135854  0.120295  0.148122  \n",
      "\n",
      "[370 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "task_csv = '../runs_trainings/decremental_multiclass/normal/seed_0/incdec_rNNMEbbU/error_analysis/task_0_test_error_analysis.csv'\n",
    "task_data = pd.read_csv(task_csv)\n",
    "print(task_data)\n",
    "# this is used later to create the class_to_idx\n",
    "def kinetics_classes(classes_csv):\n",
    "    df = pd.read_csv(classes_csv)\n",
    "    classes_behaviors = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        class_name = row['Class']\n",
    "        subcategory = row['Subcategory']\n",
    "        \n",
    "        # Check if the class_name is already in the dictionary, if not, create a new entry\n",
    "        if class_name not in classes_behaviors:\n",
    "            classes_behaviors[class_name] = []\n",
    "        \n",
    "        # Add the subcategory to the corresponding class_name entry in the dictionary\n",
    "        classes_behaviors[class_name].append(subcategory)\n",
    "\n",
    "    return classes_behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a mapping between classes - behaviors\n",
    "folder_csv = '../Kinetics/Info/'\n",
    "class_csv = os.path.join(folder_csv, 'classes.csv')\n",
    "classes_behaviors = kinetics_classes(class_csv)\n",
    "\n",
    "#create a index for each class -- {class: idx}\n",
    "class_to_idx = {key: i for i, key in enumerate(classes_behaviors.keys())}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_names = ['food', 'phone','smoking','fatigue','selfcare']\n",
    "targets_names = ['target_food','target_phone','target_smoking','target_fatigue','target_selfcare']\n",
    "\n",
    "criterion_type = 'multiclass'\n",
    "#criterion_type = 'multilabel'\n",
    "\n",
    "predictions_list = []\n",
    "targets_list = []\n",
    "for i in range(len(predictions_names)):\n",
    "    if criterion_type == 'multilabel':\n",
    "        class_targets = task_data[targets_names[i]].tolist()\n",
    "        targets_list.append(class_targets)\n",
    "    class_predictions = task_data[predictions_names[i]].tolist()\n",
    "    predictions_list.append(class_predictions)\n",
    "   \n",
    "predictions = torch.Tensor(predictions_list).permute(1,0)\n",
    "if criterion_type == 'multilabel':\n",
    "    targets = torch.Tensor(targets_list).permute(1,0)\n",
    "else:\n",
    "    targets = torch.Tensor(task_data['target'])\n",
    "\n",
    "subcategory = task_data['subcategory']\n",
    "data_path = task_data['video_path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_behaviors_dict = {\n",
    "    'food': [\n",
    "        'eating burger', 'eating cake', 'eating carrots', 'eating chips', 'eating doughnuts',\n",
    "        'eating hotdog', 'eating ice cream', 'eating spaghetti', 'eating watermelon',\n",
    "        'sucking lolly', 'tasting beer', 'tasting food', 'tasting wine', 'sipping cup'\n",
    "    ],\n",
    "    'phone': [\n",
    "        'texting', 'talking on cell phone', 'looking at phone'\n",
    "    ],\n",
    "    'smoking': [\n",
    "        'smoking', 'smoking hookah', 'smoking pipe'\n",
    "    ],\n",
    "    'fatigue': [\n",
    "        'sleeping', 'yawning', 'headbanging', 'headbutting', 'shaking head'\n",
    "    ],\n",
    "    'selfcare': [\n",
    "        'scrubbing face', 'putting in contact lenses', 'putting on eyeliner', 'putting on foundation',\n",
    "        'putting on lipstick', 'putting on mascara', 'brushing hair', 'brushing teeth', 'braiding hair',\n",
    "        'combing hair', 'dyeing eyebrows', 'dyeing hair'\n",
    "    ]\n",
    "    }\n",
    "\n",
    "\n",
    "if criterion_type == 'multilabel':\n",
    "    binarized_targets = targets\n",
    "    targets = torch.Tensor(torch.argmax(targets, axis=1))\n",
    "else:\n",
    "    binarized_targets = torch.Tensor(label_binarize(targets, classes=[i for i in range(5)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_eval = MetricEvaluatorIncDec('../random_tries/', num_classes=5, criterion_type=criterion_type, all_behaviors_dict=all_behaviors_dict, class_to_idx=class_to_idx)\n",
    "metric_eval.update(targets, binarized_targets, predictions, subcategory, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - task accuracy: 0.5243243243243243\n",
      " - task average precision: tensor([0.6371, 0.1971, 0.1325, 0.3346, 0.7209])\n",
      " - task acc per class: [0.7162162162162162, 0.8783783783783784, 0.918918918918919, 0.7756756756756756, 0.7594594594594595]\n",
      " - task precision per class: tensor([0.6316, 0.2581, 0.0000, 0.2857, 0.6202])\n",
      " - task recall per class: tensor([0.6000, 0.2667, 0.0000, 0.4400, 0.6667])\n",
      " - task mAP: 0.40442556142807007\n",
      " - task weighted mAP: 0.5467880964279175\n"
     ]
    }
   ],
   "source": [
    "acc, ap, acc_per_class, mean_ap, map_weighted, precision_per_class, recall_per_class, exact_match, ap_per_subcat, recall_per_subcat = metric_eval.get(verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eating burger': tensor(0.1075), 'eating cake': tensor(0.2492), 'eating carrots': tensor(0.1255), 'eating chips': tensor(0.0615), 'eating doughnuts': tensor(0.1944), 'eating hotdog': tensor(0.1697), 'eating ice cream': tensor(0.1299), 'eating spaghetti': tensor(0.1538), 'eating watermelon': tensor(0.3146), 'sucking lolly': tensor(0.0973), 'tasting beer': tensor(0.1124), 'tasting food': tensor(0.1410), 'tasting wine': tensor(0.0949), 'sipping cup': tensor(0.2927), 'texting': tensor(0.1300), 'talking on cell phone': tensor(0.0710), 'looking at phone': tensor(0.0743), 'smoking': tensor(0.0449), 'smoking hookah': tensor(0.0649), 'smoking pipe': tensor(0.0563), 'sleeping': tensor(0.0717), 'yawning': tensor(0.1361), 'headbanging': tensor(0.3075), 'headbutting': tensor(0.1731), 'shaking head': tensor(0.0475), 'scrubbing face': tensor(0.5530), 'putting in contact lenses': tensor(0.3533), 'putting on eyeliner': tensor(0.5247), 'putting on foundation': tensor(0.4476), 'putting on lipstick': tensor(0.3000), 'putting on mascara': tensor(0.5585), 'brushing hair': tensor(0.0940), 'brushing teeth': tensor(0.1125), 'braiding hair': tensor(0.2056), 'combing hair': tensor(0.0461), 'dyeing eyebrows': tensor(0.7735), 'dyeing hair': tensor(0.2267)}\n",
      "{'eating burger': tensor(0.5000), 'eating cake': tensor(0.9000), 'eating carrots': tensor(0.6000), 'eating chips': tensor(0.3000), 'eating doughnuts': tensor(0.7000), 'eating hotdog': tensor(0.6000), 'eating ice cream': tensor(0.5000), 'eating spaghetti': tensor(0.5000), 'eating watermelon': tensor(0.7000), 'sucking lolly': tensor(0.3000), 'tasting beer': tensor(0.7000), 'tasting food': tensor(0.7000), 'tasting wine': tensor(0.6000), 'sipping cup': tensor(0.8000), 'texting': tensor(0.4000), 'talking on cell phone': tensor(0.2000), 'looking at phone': tensor(0.2000), 'smoking': tensor(0.), 'smoking hookah': tensor(0.), 'smoking pipe': tensor(0.), 'sleeping': tensor(0.4000), 'yawning': tensor(0.4000), 'headbanging': tensor(0.9000), 'headbutting': tensor(0.3000), 'shaking head': tensor(0.2000), 'scrubbing face': tensor(0.9000), 'putting in contact lenses': tensor(0.7000), 'putting on eyeliner': tensor(0.8000), 'putting on foundation': tensor(0.9000), 'putting on lipstick': tensor(0.8000), 'putting on mascara': tensor(0.9000), 'brushing hair': tensor(0.3000), 'brushing teeth': tensor(0.5000), 'braiding hair': tensor(0.4000), 'combing hair': tensor(0.2000), 'dyeing eyebrows': tensor(1.), 'dyeing hair': tensor(0.6000)}\n"
     ]
    }
   ],
   "source": [
    "print(ap_per_subcat)\n",
    "print(recall_per_subcat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_incdec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
