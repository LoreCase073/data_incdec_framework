{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports to work with...\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay, average_precision_score\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = [\n",
    "                '../runs_trainings/no_freeze/multilabel/weighted',\n",
    "                '../runs_trainings/no_freeze/joint_incremental_multilabel/weighted',\n",
    "                '../runs_trainings/no_freeze/incremental_decremental_multilabel/weighted',\n",
    "                '../runs_trainings/no_freeze/decremental_multilabel/weighted',\n",
    "\n",
    "                '../runs_trainings/freeze_backbone/baseline_multilabel/weighted/new',\n",
    "                '../runs_trainings/freeze_backbone/joint_incremental_multilabel/weighted/new',\n",
    "                '../runs_trainings/freeze_backbone/incremental_decremental_multilabel/weighted/new',\n",
    "                '../runs_trainings/freeze_backbone/decremental_multilabel/weighted/new',\n",
    "\n",
    "                '../runs_trainings/lwf/baseline/lambda_1',\n",
    "                '../runs_trainings/lwf/joint_incremental/lambda_1',\n",
    "                '../runs_trainings/lwf/incremental_decremental/lambda_1/temp_1',\n",
    "                '../runs_trainings/lwf/decremental/lambda_1',\n",
    "\n",
    "                '../runs_trainings/lwf/baseline/lambda_1',\n",
    "                '../runs_trainings/fd/joint_incremental/lambda_01',\n",
    "                '../runs_trainings/fd/incremental_decremental/lambda_01',\n",
    "                '../runs_trainings/fd/decremental/lambda_01',\n",
    "                ]\n",
    "save_exp_name = [\n",
    "                'no_freeze_baseline',\n",
    "                'no_freeze_joint',\n",
    "                'no_freeze_incdec',\n",
    "                'no_freeze_dec',\n",
    "                \n",
    "                'freeze_baseline',\n",
    "                'freeze_joint',\n",
    "                'freeze_incdec',\n",
    "                'freeze_dec',\n",
    "\n",
    "                'lwf_baseline',\n",
    "                'lwf_joint',\n",
    "                'lwf_incdec',\n",
    "                'lwf_dec',\n",
    "\n",
    "                'fd_baseline',\n",
    "                'fd_joint',\n",
    "                'fd_incdec',\n",
    "                'fd_dec',\n",
    "                 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(task_dataframe):\n",
    "    predictions_names = ['food', 'phone','smoking','fatigue','selfcare']\n",
    "    targets_names = ['target_food','target_phone','target_smoking','target_fatigue','target_selfcare']\n",
    "    probabilities = []\n",
    "    targets = []\n",
    "    for i in range(len(predictions_names)):\n",
    "        class_targets = task_dataframe[targets_names[i]].tolist()\n",
    "        targets.append(class_targets)\n",
    "        class_predictions = task_dataframe[predictions_names[i]].tolist()\n",
    "        probabilities.append(class_predictions)\n",
    "    \n",
    "    \n",
    "    return probabilities, targets\n",
    "\n",
    "\n",
    "def extract_subcategory_data(task_dataframe, class_name, subcategory):\n",
    "    predictions_names = ['food', 'phone','smoking','fatigue','selfcare']\n",
    "    targets_names = ['target_food','target_phone','target_smoking','target_fatigue','target_selfcare']\n",
    "    \n",
    "    probabilities = []\n",
    "    targets = []\n",
    "    subcat_dataframe = task_dataframe[task_dataframe[\"subcategory\"] == subcategory]\n",
    "    idx_class = predictions_names.index(class_name)\n",
    "    other_classes_dataframe = task_dataframe[task_dataframe[targets_names[idx_class]] != 1]\n",
    "    new_dataframe = pd.concat([subcat_dataframe,other_classes_dataframe])\n",
    "    for i in range(len(predictions_names)):\n",
    "        class_targets = new_dataframe[targets_names[i]].tolist()\n",
    "        targets.append(class_targets)\n",
    "        class_predictions = new_dataframe[predictions_names[i]].tolist()\n",
    "        probabilities.append(class_predictions)\n",
    "    \n",
    "    \n",
    "    return probabilities, targets\n",
    "\n",
    "\n",
    "def get_precision_recall_for_prcurve(probabilities, labels, num_classes):\n",
    "     # precision recall curve\n",
    "        Y = labels\n",
    "        precision = dict()\n",
    "        recall = dict()\n",
    "        ap = dict()\n",
    "        \n",
    "        for i in range(num_classes):\n",
    "            precision[i], recall[i], _ = precision_recall_curve(Y[:, i],probabilities[:, i])\n",
    "            ap[i] = average_precision_score(Y[:, i],probabilities[:, i])\n",
    "\n",
    "\n",
    "        return precision, recall, ap\n",
    "\n",
    "\n",
    "def get_precision_recall_for_prcurve_subcat(probabilities, labels, num_classes, idx_class):\n",
    "     # precision recall curve\n",
    "        Y = labels\n",
    "        precision = dict()\n",
    "        recall = dict()\n",
    "        ap = dict()\n",
    "        for i in range(num_classes):\n",
    "            precision[i], recall[i], _ = precision_recall_curve(Y[:, i],probabilities[:, i])\n",
    "            ap[i] = average_precision_score(Y[:, i],probabilities[:, i])\n",
    "\n",
    "\n",
    "        return precision[idx_class], recall[idx_class], ap[idx_class]\n",
    "\n",
    "\n",
    "def plot_pr_curve(precision, recall, ap, num_tasks, idx_class, class_name, output_path):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        figure, ax = plt.subplots(figsize=(8, 8))\n",
    "        for i in range(num_tasks):\n",
    "            if i == 0 or i==num_tasks-1:\n",
    "                display = PrecisionRecallDisplay(\n",
    "                    recall=recall[i][idx_class],\n",
    "                    precision=precision[i][idx_class],\n",
    "                    average_precision=ap[i][idx_class],\n",
    "                )\n",
    "                if i==0:\n",
    "                    display.plot(ax=ax, name=f\"PR Curve for task_id {i} for class {class_name}\")\n",
    "                else:\n",
    "                    display.plot(ax=ax, name=f\"PR Curve for task_id {i} for class {class_name}\", ls='--')\n",
    "                ax.legend(loc=0)\n",
    "        figure.savefig(output_path + '/' + class_name + '.png')\n",
    "        \n",
    "        plt.close(figure)\n",
    "\n",
    "\n",
    "def plot_pr_curve_seeds(precision, recall, ap, seeds, num_tasks, idx_class, class_name, output_path):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        figure, ax = plt.subplots(figsize=(8, 8))\n",
    "        for idx_seed in seeds:\n",
    "            for i in range(num_tasks):\n",
    "                if i == 0 or i==num_tasks-1:\n",
    "                    display = PrecisionRecallDisplay(\n",
    "                        recall=recall[idx_seed][i][idx_class],\n",
    "                        precision=precision[idx_seed][i][idx_class],\n",
    "                        average_precision=ap[idx_seed][i][idx_class],\n",
    "                    )\n",
    "                    if i==0:\n",
    "                        display.plot(ax=ax, name=f\"PR Curve for task_id {i} for class {class_name} seed {idx_seed}\")\n",
    "                    else:\n",
    "                        display.plot(ax=ax, name=f\"PR Curve for task_id {i} for class {class_name} seed {idx_seed}\", ls='--')\n",
    "                    ax.legend(loc=0)\n",
    "        figure.savefig(output_path + '/' + class_name + '.png')\n",
    "        \n",
    "        plt.close(figure)\n",
    "\n",
    "def plot_pr_curve_subcat(precision, recall, ap, num_tasks, subcat_name, output_path):\n",
    "        \"\"\"\n",
    "        Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "        \"\"\"\n",
    "\n",
    "        figure, ax = plt.subplots(figsize=(8, 8))\n",
    "        for i in range(num_tasks):\n",
    "            if i == 0 or i==num_tasks-1:\n",
    "                display = PrecisionRecallDisplay(\n",
    "                    recall=recall[i],\n",
    "                    precision=precision[i],\n",
    "                    average_precision=ap[i],\n",
    "                )\n",
    "                display.plot(ax=ax, name=f\"Precision-recall for task_id {i} for class {subcat_name}\")\n",
    "        figure.savefig(output_path + '/' + subcat_name + '.png')\n",
    "        plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a version where i do it just for 3 seeds\n",
    "seeds = [0,1,2]\n",
    "output_path = '../statistics_to_save/pr_curves/three_seeds/'\n",
    "for idx_exp in range (len(results_path)):  \n",
    "    output_name_path = os.path.join(output_path,save_exp_name[idx_exp])\n",
    "    if not os.path.exists(output_name_path):\n",
    "            os.mkdir(output_name_path)\n",
    "\n",
    "    precision = []\n",
    "    recall = []\n",
    "    ap = []\n",
    "    \n",
    "    precision_micro = []\n",
    "    recall_micro = []\n",
    "    for idx_seed in seeds:  \n",
    "        seed_path = os.path.join(results_path[idx_exp],'seed_' + str(idx_seed))\n",
    "        seed_precision = []\n",
    "        seed_recall = []\n",
    "        seed_ap = []\n",
    "        for name_exp in os.listdir(seed_path):\n",
    "            exp_path = os.path.join(seed_path,name_exp)\n",
    "            ea_name = 'error_analysis'\n",
    "            ea_path = os.path.join(exp_path,ea_name)\n",
    "            for i in range(6):\n",
    "                task_name = 'task_' + str(i) + '_test_error_analysis.csv'\n",
    "                task_ea_path = os.path.join(ea_path,task_name)\n",
    "                task_dataframe = pd.read_csv(task_ea_path)\n",
    "                tmp_probabilities, tmp_targets = extract_data(task_dataframe)\n",
    "                probabilities = torch.Tensor(tmp_probabilities).permute(1,0).numpy()\n",
    "                targets = torch.Tensor(tmp_targets).permute(1,0).numpy()\n",
    "                \n",
    "                tmp_precision, tmp_recall, tmp_ap = get_precision_recall_for_prcurve(probabilities,targets,5)\n",
    "                seed_precision.append(tmp_precision)\n",
    "                seed_recall.append(tmp_recall)\n",
    "                seed_ap.append(tmp_ap)\n",
    "        precision.append(seed_precision)\n",
    "        recall.append(seed_recall)\n",
    "        ap.append(seed_ap)\n",
    "\n",
    "    classes = ['food', 'phone','smoking','fatigue','selfcare']\n",
    "    for idx_class in range(len(classes)):\n",
    "        plot_pr_curve_seeds(precision, recall, ap, seeds, 6, idx_class, classes[idx_class], output_name_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a version where i do it just for 1 seed each\n",
    "seeds = [0,1,2]\n",
    "\n",
    "\n",
    "    \n",
    "for idx_exp in range (len(results_path)): \n",
    "    precision_micro = []\n",
    "    recall_micro = []\n",
    "    for idx_seed in seeds:  \n",
    "        seed_path = os.path.join(results_path[idx_exp],'seed_' + str(idx_seed))\n",
    "        output_path = '../statistics_to_save/pr_curves/{}_seed/'.format(idx_seed)\n",
    "        if not os.path.exists(output_path):\n",
    "            os.mkdir(output_path)\n",
    "         \n",
    "        output_name_path = os.path.join(output_path,save_exp_name[idx_exp])\n",
    "        if not os.path.exists(output_name_path):\n",
    "                os.mkdir(output_name_path)\n",
    "        precision = []\n",
    "        recall = []\n",
    "        ap = []\n",
    "        for name_exp in os.listdir(seed_path):\n",
    "            exp_path = os.path.join(seed_path,name_exp)\n",
    "            ea_name = 'error_analysis'\n",
    "            ea_path = os.path.join(exp_path,ea_name)\n",
    "            for i in range(6):\n",
    "                task_name = 'task_' + str(i) + '_test_error_analysis.csv'\n",
    "                task_ea_path = os.path.join(ea_path,task_name)\n",
    "                task_dataframe = pd.read_csv(task_ea_path)\n",
    "                tmp_probabilities, tmp_targets = extract_data(task_dataframe)\n",
    "                probabilities = torch.Tensor(tmp_probabilities).permute(1,0).numpy()\n",
    "                targets = torch.Tensor(tmp_targets).permute(1,0).numpy()\n",
    "                \n",
    "                tmp_precision, tmp_recall, tmp_ap = get_precision_recall_for_prcurve(probabilities,targets,5)\n",
    "                precision.append(tmp_precision)\n",
    "                recall.append(tmp_recall)\n",
    "                ap.append(tmp_ap)\n",
    "\n",
    "            classes = ['food', 'phone','smoking','fatigue','selfcare']\n",
    "            for idx_class in range(len(classes)):\n",
    "                plot_pr_curve(precision, recall, ap, 6, idx_class, classes[idx_class], output_name_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" data_dict = {\\n    'food': [\\n        'eating burger', 'eating cake', 'eating carrots', 'eating chips', 'eating doughnuts',\\n        'eating hotdog', 'eating ice cream', 'eating spaghetti', 'eating watermelon',\\n        'sucking lolly', 'tasting beer', 'tasting food', 'tasting wine', 'sipping cup'\\n    ],\\n    'phone': [\\n        'texting', 'talking on cell phone', 'looking at phone'\\n    ],\\n    'smoking': [\\n        'smoking', 'smoking hookah', 'smoking pipe'\\n    ],\\n    'fatigue': [\\n        'sleeping', 'yawning', 'headbanging', 'headbutting', 'shaking head'\\n    ],\\n    'selfcare': [\\n        'scrubbing face', 'putting in contact lenses', 'putting on eyeliner', 'putting on foundation',\\n        'putting on lipstick', 'putting on mascara', 'brushing hair', 'brushing teeth', 'braiding hair',\\n        'combing hair', 'dyeing eyebrows', 'dyeing hair'\\n    ]\\n    } \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" data_dict = {\n",
    "    'food': [\n",
    "        'eating burger', 'eating cake', 'eating carrots', 'eating chips', 'eating doughnuts',\n",
    "        'eating hotdog', 'eating ice cream', 'eating spaghetti', 'eating watermelon',\n",
    "        'sucking lolly', 'tasting beer', 'tasting food', 'tasting wine', 'sipping cup'\n",
    "    ],\n",
    "    'phone': [\n",
    "        'texting', 'talking on cell phone', 'looking at phone'\n",
    "    ],\n",
    "    'smoking': [\n",
    "        'smoking', 'smoking hookah', 'smoking pipe'\n",
    "    ],\n",
    "    'fatigue': [\n",
    "        'sleeping', 'yawning', 'headbanging', 'headbutting', 'shaking head'\n",
    "    ],\n",
    "    'selfcare': [\n",
    "        'scrubbing face', 'putting in contact lenses', 'putting on eyeliner', 'putting on foundation',\n",
    "        'putting on lipstick', 'putting on mascara', 'brushing hair', 'brushing teeth', 'braiding hair',\n",
    "        'combing hair', 'dyeing eyebrows', 'dyeing hair'\n",
    "    ]\n",
    "    } \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" #this is a version where i do it just for 1 seed each but for each subcategory\\nseeds = [0,1,2]\\n\\n\\n    \\nfor idx_exp in range (len(results_path)): \\n    precision_micro = []\\n    recall_micro = []\\n    for idx_seed in seeds:\\n        seed_path = os.path.join(results_path[idx_exp],'seed_' + str(idx_seed))\\n        output_path = '../statistics_to_save/pr_curves/{}_seed/'.format(idx_seed)\\n        if not os.path.exists(output_path):\\n            os.mkdir(output_path)\\n\\n        subcat_path = os.path.join(output_path,'subcategories')\\n        if not os.path.exists(subcat_path):\\n            os.mkdir(subcat_path)\\n         \\n        output_name_path = os.path.join(subcat_path,save_exp_name[idx_exp])\\n        if not os.path.exists(output_name_path):\\n                os.mkdir(output_name_path)\\n        \\n        for name_exp in os.listdir(seed_path):\\n            exp_path = os.path.join(seed_path,name_exp)\\n            ea_name = 'error_analysis'\\n            ea_path = os.path.join(exp_path,ea_name)\\n\\n            # now iterate over subcategories\\n\\n            classes = ['food', 'phone','smoking','fatigue','selfcare']\\n\\n            for class_name in classes:\\n                for subcat in data_dict[class_name]:\\n                    precision = []\\n                    recall = []\\n                    ap = []\\n                    for i in range(6):\\n                        task_name = 'task_' + str(i) + '_test_error_analysis.csv'\\n                        task_ea_path = os.path.join(ea_path,task_name)\\n                        task_dataframe = pd.read_csv(task_ea_path)\\n                        tmp_probabilities, tmp_targets = extract_subcategory_data(task_dataframe,class_name,subcat)\\n                        probabilities = torch.Tensor(tmp_probabilities).permute(1,0).numpy()\\n                        targets = torch.Tensor(tmp_targets).permute(1,0).numpy()\\n                        \\n                        tmp_precision, tmp_recall, tmp_ap = get_precision_recall_for_prcurve_subcat(probabilities,targets,len(classes),classes.index(class_name))\\n                        precision.append(tmp_precision)\\n                        recall.append(tmp_recall)\\n                        ap.append(tmp_ap)\\n                    plot_pr_curve_subcat(precision,recall,ap,6,subcat,output_name_path)\\n \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" #this is a version where i do it just for 1 seed each but for each subcategory\n",
    "seeds = [0,1,2]\n",
    "\n",
    "\n",
    "    \n",
    "for idx_exp in range (len(results_path)): \n",
    "    precision_micro = []\n",
    "    recall_micro = []\n",
    "    for idx_seed in seeds:\n",
    "        seed_path = os.path.join(results_path[idx_exp],'seed_' + str(idx_seed))\n",
    "        output_path = '../statistics_to_save/pr_curves/{}_seed/'.format(idx_seed)\n",
    "        if not os.path.exists(output_path):\n",
    "            os.mkdir(output_path)\n",
    "\n",
    "        subcat_path = os.path.join(output_path,'subcategories')\n",
    "        if not os.path.exists(subcat_path):\n",
    "            os.mkdir(subcat_path)\n",
    "         \n",
    "        output_name_path = os.path.join(subcat_path,save_exp_name[idx_exp])\n",
    "        if not os.path.exists(output_name_path):\n",
    "                os.mkdir(output_name_path)\n",
    "        \n",
    "        for name_exp in os.listdir(seed_path):\n",
    "            exp_path = os.path.join(seed_path,name_exp)\n",
    "            ea_name = 'error_analysis'\n",
    "            ea_path = os.path.join(exp_path,ea_name)\n",
    "\n",
    "            # now iterate over subcategories\n",
    "\n",
    "            classes = ['food', 'phone','smoking','fatigue','selfcare']\n",
    "\n",
    "            for class_name in classes:\n",
    "                for subcat in data_dict[class_name]:\n",
    "                    precision = []\n",
    "                    recall = []\n",
    "                    ap = []\n",
    "                    for i in range(6):\n",
    "                        task_name = 'task_' + str(i) + '_test_error_analysis.csv'\n",
    "                        task_ea_path = os.path.join(ea_path,task_name)\n",
    "                        task_dataframe = pd.read_csv(task_ea_path)\n",
    "                        tmp_probabilities, tmp_targets = extract_subcategory_data(task_dataframe,class_name,subcat)\n",
    "                        probabilities = torch.Tensor(tmp_probabilities).permute(1,0).numpy()\n",
    "                        targets = torch.Tensor(tmp_targets).permute(1,0).numpy()\n",
    "                        \n",
    "                        tmp_precision, tmp_recall, tmp_ap = get_precision_recall_for_prcurve_subcat(probabilities,targets,len(classes),classes.index(class_name))\n",
    "                        precision.append(tmp_precision)\n",
    "                        recall.append(tmp_recall)\n",
    "                        ap.append(tmp_ap)\n",
    "                    plot_pr_curve_subcat(precision,recall,ap,6,subcat,output_name_path)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" seeds = [0,1,2]\\n#this is a version where i put all the examples from all three seeds\\noutput_path = '../statistics_to_save/pr_curves/'\\nfor idx_exp in range (len(results_path)):  \\n    output_name_path = os.path.join(output_path,save_exp_name[idx_exp])\\n    if not os.path.exists(output_name_path):\\n            os.mkdir(output_name_path)\\n\\n    precision = []\\n    recall = []\\n    precision_micro = []\\n    recall_micro = []\\n    for i in range(6):\\n        task_name = 'task_' + str(i) + '_test_error_analysis.csv'\\n        probabilities = []\\n        targets = []\\n        \\n        for idx_seed in seeds:  \\n            seed_path = os.path.join(results_path[idx_exp],'seed_' + str(idx_seed))\\n            for name_exp in os.listdir(seed_path):\\n                exp_path = os.path.join(seed_path,name_exp)\\n                ea_name = 'error_analysis'\\n                ea_path = os.path.join(exp_path,ea_name)\\n                \\n                task_ea_path = os.path.join(ea_path,task_name)\\n                task_dataframe = pd.read_csv(task_ea_path)\\n                tmp_probabilities, tmp_targets = extract_data(task_dataframe)\\n                probabilities.append(torch.Tensor(tmp_probabilities).permute(1,0))\\n                targets.append(torch.Tensor(tmp_targets).permute(1,0))\\n\\n        probabilities = torch.cat(probabilities,0).numpy()\\n        targets = torch.cat(targets,0).numpy()\\n        \\n        tmp_precision, tmp_recall = get_precision_recall_for_prcurve(probabilities,targets,5)\\n        precision.append(tmp_precision)\\n        recall.append(tmp_recall)\\n\\n\\n\\n    classes = ['food', 'phone','smoking','fatigue','selfcare']\\n    for idx_class in range(len(classes)):\\n        plot_pr_curve(precision, recall, 6, idx_class, classes[idx_class], output_name_path) \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" seeds = [0,1,2]\n",
    "#this is a version where i put all the examples from all three seeds\n",
    "output_path = '../statistics_to_save/pr_curves/'\n",
    "for idx_exp in range (len(results_path)):  \n",
    "    output_name_path = os.path.join(output_path,save_exp_name[idx_exp])\n",
    "    if not os.path.exists(output_name_path):\n",
    "            os.mkdir(output_name_path)\n",
    "\n",
    "    precision = []\n",
    "    recall = []\n",
    "    precision_micro = []\n",
    "    recall_micro = []\n",
    "    for i in range(6):\n",
    "        task_name = 'task_' + str(i) + '_test_error_analysis.csv'\n",
    "        probabilities = []\n",
    "        targets = []\n",
    "        \n",
    "        for idx_seed in seeds:  \n",
    "            seed_path = os.path.join(results_path[idx_exp],'seed_' + str(idx_seed))\n",
    "            for name_exp in os.listdir(seed_path):\n",
    "                exp_path = os.path.join(seed_path,name_exp)\n",
    "                ea_name = 'error_analysis'\n",
    "                ea_path = os.path.join(exp_path,ea_name)\n",
    "                \n",
    "                task_ea_path = os.path.join(ea_path,task_name)\n",
    "                task_dataframe = pd.read_csv(task_ea_path)\n",
    "                tmp_probabilities, tmp_targets = extract_data(task_dataframe)\n",
    "                probabilities.append(torch.Tensor(tmp_probabilities).permute(1,0))\n",
    "                targets.append(torch.Tensor(tmp_targets).permute(1,0))\n",
    "\n",
    "        probabilities = torch.cat(probabilities,0).numpy()\n",
    "        targets = torch.cat(targets,0).numpy()\n",
    "        \n",
    "        tmp_precision, tmp_recall = get_precision_recall_for_prcurve(probabilities,targets,5)\n",
    "        precision.append(tmp_precision)\n",
    "        recall.append(tmp_recall)\n",
    "\n",
    "\n",
    "\n",
    "    classes = ['food', 'phone','smoking','fatigue','selfcare']\n",
    "    for idx_class in range(len(classes)):\n",
    "        plot_pr_curve(precision, recall, 6, idx_class, classes[idx_class], output_name_path) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_incdec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
